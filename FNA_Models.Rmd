---
title: "Breast Cancer Diagnosis using Classification"
author: "Sean Cairns"
date: "2023-11-16"
output:
  word_document: default
---


## Introduction 


## Data Exploration


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(readr)
library(rpart)
library(rpart.plot)
library(caret)
library(reshape2)
library(pROC)

```


```{r summary, echo=FALSE}
data <- read.csv("FNA_cancer.csv")
# The FNA cancer data
dimensions <- dim(data)
print(paste("Data Dimensions: Rows =", dimensions[1], ", Columns =", dimensions[2]))
```

## Shuffling the data

```{r info, echo=TRUE}

# shuffle the data
set.seed(100)
shuffle_index <- sample(1:nrow(data))
data <- data[shuffle_index, ]
head(data)
```
```{r diagnosis plot, echo=TRUE, fig.height=5, fig.width=5}

diagnosis_plot <- ggplot(data, aes(x = diagnosis)) +
  geom_bar(fill = "skyblue") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
        plot.background = element_rect(fill = "white"),
        panel.background = element_rect(fill = "white")) +
  labs(title = "Diagnosis Results",
       x = "Type",
       y = "Count")
ggsave("./Images/Diagnosis.png", plot = diagnosis_plot, width = 8, height = 6, dpi = 300)

diagnosis_plot

```

## Cleaning the data
```{r cleaning, echo=TRUE}
# Drop unwanted variable(s) and null values
data <- data %>% select(-c(X)) %>%
na.omit()
head(data)
```
```{r cor, echo=TRUE, fig.height=10, fig.width=10}

heatmap_data <- data[, -which(names(data) == 'diagnosis')]
cor_mat <- melt(cor(heatmap_data))

cor_heatmap <- ggplot(cor_mat, aes(Var1, Var2, fill = value)) +
  geom_tile() + 
  scale_fill_gradient(low='white', high = "red") + 
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
        plot.background = element_rect(fill = "white"),
        panel.background = element_rect(fill = "white")) + 
  labs(title = "Correlation Heatmap between FNA_Cancer Variables",
       x = "Variables",
       y = "Variables")
ggsave("cor_heatmap.png", plot = cor_heatmap, width = 8, height = 6, dpi = 300)

cor_heatmap
```


## Creating the train and test set
```{r splitting, echo=TRUE}

target <- data$diagnosis
train_indices <- createDataPartition(target, p = 0.8, list = FALSE)

# Split data into training and test sets
train_data <- data[train_indices, ]
test_data <- data[-train_indices, ]


# Print the dimensions of the train and test data
train_dimensions <- dim(train_data)
test_dimensions <- dim(test_data)


print(paste("Train Data Dimensions: Rows =", train_dimensions[1], ", Columns =", train_dimensions[2]))
print(paste("Test Data Dimensions: Rows =", test_dimensions[1], ", Columns =", test_dimensions[2]))



```


# Decision Tree Model 
```{r model1, echo=TRUE}
# List of parameters
ctrl <- trainControl(method = "cv", 
                     number = 10, 
                     search = "random", 
                     verboseIter = FALSE, 
                     classProbs = TRUE
                     )

# List of hyper parameters to loop through
hyper_grid <- expand.grid(
  cp = runif(100, min = 0.01, max = 0.5)
)


# Training model
dt_model <- train(
  diagnosis ~ .,
  data = train_data, # Need to recombine features and target for gridsearch
  method = "rpart",
  trControl = ctrl,
  tuneGrid = hyper_grid
  
)
print(dt_model)

```

```{r bestmodel, echo=TRUE}
# Getting best model
best_model <- dt_model$finalModel
# Plotting model
rpart.plot(best_model, extra = 105)
```
## Showing Feature Importance
```{r featureimport, echo=FALSE}
feature_importance <- varImp(dt_model)
print(feature_importance)
```

## Predict testing Data Based off of Training Model
```{r confmatrix, echo=TRUE}
# Predicting new data to see performance
predictions <- predict(best_model, newdata = test_data, type= 'class')

# Reformatting data to fit confusion matrix
actual_labels <- factor(test_data$diagnosis, levels = c("B", "M"))
predicted_labels <- factor(predictions, levels = c("B", "M"))

# Creating confusion matrix
conf_mat <- confusionMatrix(data = predicted_labels, reference = actual_labels)
conf_mat
```

```{r confusion matrix, echo=TRUE, fig.height=5, fig.width=5}
cm = as.data.frame(conf_mat$table)

conf_plot <- ggplot(data = cm, aes(x = Reference, y = Prediction, fill = Freq)) +
  geom_tile() +
  geom_text(aes(label = Freq), vjust = 1) +
  labs(x = "Actual", y = "Predicted", title = "Decision Tree Confusion Matrix") +
  scale_fill_gradient(low = "white", high = "green") +  # Adjust colors as needed
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
        plot.background = element_rect(fill = "white"),
        panel.background = element_rect(fill = "white"))
  
ggsave("./Images/DecisionTree_Confusion_Matrix.png", plot = conf_plot, width = 8, height = 6, dpi = 300)
conf_plot
  
```

```{r importance plot, echo=TRUE, fig.height=5, fig.width=5}
importance <- as.data.frame(varImp(best_model))

importance_scores <- importance$Overall
importance_labels <- rownames(importance)
importance_data <- data.frame(importance_scores, importance_labels)

importance_plot <- ggplot(data = head(importance_data, 6), aes(x = reorder(importance_labels, -importance_scores), y = importance_scores)) + 
  labs(x = "Variables", y = "Importance", title = "Decision Tree Feature Importance Scores") +
  geom_bar(stat = "identity", fill = "skyblue") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
        plot.background = element_rect(fill = "white"),
        panel.background = element_rect(fill = "white"))
  
ggsave("./Images/DecisionTree_Importance_Plot.png", plot = importance_plot, width = 8, height = 6, dpi = 300)
importance_plot
  
```
```{r Logistic ROC plot, echo=TRUE}

# Assuming 'predictions' contains class labels from the decision tree
# Convert predicted labels to binary probabilities
predicted_probabilities <- ifelse(predictions == "M", 1, 0)  # Assuming 'M' represents positive class

# Compute ROC curve
roc_curve <- roc(actual_labels, predicted_probabilities)

# Plot ROC curve using ggplot
plot(roc_curve)
```

## Logistic Model
```{r model2, echo=TRUE}
# Converting the factor levels to a binary format for logistic regression model
# 1 = 'M' (malignant) 0 = 'B' (benign)
train_data$diagnosis <- as.factor(ifelse(train_data$diagnosis == "M", 1, 0))
test_data$diagnosis <- as.factor(ifelse(test_data$diagnosis == "M", 1, 0))

# Train a logistic regression model using the glm function with binomial family parameter
logistic_model <- glm(diagnosis ~ ., data = train_data, family = "binomial")

# Summary of the model to view coefficients and statistics
summary(logistic_model)


```
## Logistical Confusion Matrix
```{r confusion matrix 2, echo=TRUE}
# Make predictions on the test data
predictions <- predict(logistic_model, newdata = test_data, type = "response")

# Convert predicted probabilities to binary predictions based on a 0.5 cutoff
binary_predictions <- ifelse(predictions > 0.5, "1", "0")

# Create a confusion matrix to evaluate the model
confusion_matrix <- confusionMatrix(as.factor(binary_predictions), test_data$diagnosis)

```

```{r confmatrix plot, echo=TRUE}
## PLOTTING CONFUSION MATRIX
cm = as.data.frame(confusion_matrix$table)

conf_plot <- ggplot(data = cm, aes(x = Reference, y = Prediction, fill = Freq)) +
  geom_tile() +
  geom_text(aes(label = Freq), vjust = 1) +
  labs(x = "Actual", y = "Predicted", title = "Logistic Regression Confusion Matrix") +
  scale_fill_gradient(low = "white", high = "green") +  # Adjust colors as needed
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
        plot.background = element_rect(fill = "white"),
        panel.background = element_rect(fill = "white"))
ggsave("./Images/Logistic_ConfusionMatrix_Plot.png", plot = importance_plot, width = 8, height = 6, dpi = 300)

print(conf_plot)
```

```{r logistic Feature Importance plot, echo=TRUE}
importance <- as.data.frame(varImp(logistic_model))

importance_scores <- importance$Overall
importance_labels <- rownames(importance)
importance_data <- data.frame(importance_scores, importance_labels)

importance_plot <- ggplot(data = head(importance_data, 6), aes(x = reorder(importance_labels, -importance_scores), y = importance_scores)) + 
  labs(x = "Variables", y = "Importance", title = "Logistic Feature Importance Scores") +
  geom_bar(stat = "identity", fill = "skyblue") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),
        plot.background = element_rect(fill = "white"),
        panel.background = element_rect(fill = "white"))
ggsave("./Images/logistic_Importance_Plot.png", plot = importance_plot, width = 8, height = 6, dpi = 300)

importance_plot
```

```{r Logistic ROC plot, echo=TRUE}
# Defining classes
binary_predictions <- ifelse(predictions > 0.5, "M", "B")
# Coping feature diagnosis
test_data$diagnosis_binary <- test_data$diagnosis

# Creating ROC curve from test and prediction datasets
roc_curve <- roc(test_data$diagnosis_binary, as.numeric(binary_predictions == "M"))

# or use plot(roc_curve) to plot curve

# creating dataframes to be used in ggplot
roc_df <- data.frame(
  FPR = roc_curve$specificities,
  TPR = roc_curve$sensitivities
)

ggplot(roc_df, aes(x = FPR, y = TPR)) +
  geom_line(color = "blue") +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +  
  labs(title = "Receiver Operating Characteristic (ROC) Curve", x = "False Positive Rate (1 - Specificity)", y = "True Positive Rate (Sensitivity)") +
  theme_minimal()

```